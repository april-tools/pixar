torchrun train.py \
    --model 'LatentGPT2' \
    --exp_type 'debug' \
    --backbone_path storage/checkpoints/debug/lpixel_pretrain/LatentGPT2/20231022-024230/20/backbone \
    --compressor_name CNNAutoencoder \
    --dataset_paths storage/cache/41c2ec0be6661800d3c5fe8d8dff1d23 \
    --max_len 3000 \
    --dataset_num_shards 256 \
    --shuffle_dataset true \
    --optim 'AdamW' \
    --lr 6e-4 \
    --beta1 0.9 \
    --beta2 0.95 \
    --decay 0.1 \
    --total_steps 3000000 \
    --stop_step 30 \
    --warm_up_step 2000 \
    --save_freq 20 \
    --eval_freq 20 \
    --seed 42 \
    --batch_size 384 \
    --sub_size 24 \
    --font_file PixeloidSans-mLxMm.ttf \
    --dpi 80 \
    --pixels_per_patch 8 \
    --patch_len 5 \
    --num_channel 1 \
    --binary true \
    --rgb false \
    --max_seq_length 1800 \
    --mix_precision fp16 \
    --half_coder false \
    --mp_workers 8 \
    --num_gpu_per_node 1 \
    --num_node 1  \
